{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.4122 - accuracy: 0.8720 - val_loss: 0.0844 - val_accuracy: 0.9747\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.1018 - accuracy: 0.9682 - val_loss: 0.0606 - val_accuracy: 0.9809\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0739 - accuracy: 0.9769 - val_loss: 0.0437 - val_accuracy: 0.9863\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0361 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 0.0349 - val_accuracy: 0.9882\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 0.0316 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 0.0321 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0388 - val_accuracy: 0.9882\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.0280 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.0297 - val_accuracy: 0.9915\n",
      "CNN Error: 0.85%\n"
     ]
    }
   ],
   "source": [
    "#Training and testing dataset from keras\n",
    "\n",
    "#importing libraries\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#split dataset into train and test\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#reshaping data, converting in grayscale, nomalizing data from 0-255 to 0-1\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "#as multiclassification problem, using hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "#creating a function to build the model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = baseline_model()\n",
    "\n",
    "#training the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "\n",
    "#evaluating the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "#saving model\n",
    "model.save('mnistCNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
